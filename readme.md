
- *readme в директории WORK*

# Отчет по лабораторной работе
## по курсу "Искусственный интеллект"

### Студенты: 

| ФИО           | Роль в проекте                                                                                            | Оценка |
| ------------- | --------------------------------------------------------------------------------------------------------- | ------ |
| Адамов А.А    | Скрипт для расставления перекрестных ссылок в тексте, составление concepts.json, темы 7-8, (10 терминов). |        |
| Ефименко К.И. | Gigachat API, картинки и md страницы, темы 3-4, (22 терминов).                                            |        |
| Нгуен Н.Х.А.  | Парсер wikidata, картинки и md страницы, темы 6-7 (15 терминов).                                          |        |
| Потапов Е.Д.  | Написание отчета, картинки и md страницы, темы 1-2 (22 термина), структура онтологии.                     |        |
| Серый Н.О.    | Написание отчета, концептуализация предметной области (все темы), структура онтологии.                    |        |

# 1. Работа с wikidata


## 1.1. Извлечение фрагментов знаний
Извлекали данные [отсюда](https://wikidata.org/) при помощи parse_wiki.py.
 
- Вход: принимает одно слово или фразу (концепцию). 
- Выход: краткое описание этой концепции.

### Алгоритм работы:

1. **Обработка входных данных**: скрипт берет переданный аргумент, нормализует его с помощью `pymorphy3`.
2. **Запрос к Wikidata**: получает QID по аргумент, извлекает его русскоязычное название из Wikidata.
3. **Запрос к Википедии**: запрашивает краткое описание из русскоязычной Википедии сначала по исходному названию, затем (если найдено) — по заголовку из Wikidata.
4. **Вывод результата**: печатает два описания — одно без использования Wikidata, второе (если найдено) с учетом заголовка оттуда.


## 1.2. Извлечение подграфа знаний
- https://wikidata.metaphacts.com/resource/app:Start


- Пример запроса:

  ```sparql
  SELECT ?item ?itemLabel WHERE {
    ?item wdt:P31 wd:Q5; 
          rdfs:label ?itemLabel.
    FILTER(LANG(?itemLabel) = "ru")
  }
  ```


- фото графа в metaphacts

## 1.3. Экспорт фрагментов графов знаний

- По возможности экспортировать фрагменты графов знаний в электронном виде, для автоматического использования в процессе написания текстов

# 2. Стадии жизни - фрагмент предметной области

## 2.1. Концептуализация



## 2.2. Онтология. Описание mermaid




# 3. Markdown-странички 

## 3.1. Gigachat API.

- Вход: Файл с запросами и API-ключ. 
- Выход: Ответы от Gigachat на каждый запрос, выведенные в консоль.

1. Инициализация:
    - Скрипт загружает API-ключ из переменной окружения GIGACHAT_API_KEY.
    - Создаётся объект Gigachat, который будет использоваться для взаимодействия с API.
    - С помощью argparse обрабатываются аргументы командной строки, чтобы получить путь к файлу с запросами.
        
2. Чтение запросов:
    - Функция read_prompts_from_file открывает указанный файл, читает его содержимое и разбивает текст на отдельные запросы по заданному разделителю (\n\n по умолчанию). Результат — список строк (prompts).
    
3. Обработка запросов:
    - Скрипт проходит по списку запросов в цикле.
    - Каждый запрос очищается от лишних пробелов (.strip()), отправляется в функцию send_to_gigachat, которая:
        - Формирует запрос к API Gigachat в виде сообщения с ролью user.    
        - Получает ответ от модели giga и возвращает его содержимое.
        
4. Вывод результата:
    - Для каждого запроса печатается сам запрос и полученный ответ.    
    - Между запросами добавляется пауза в 0.5 секунды (time.sleep(0.5)), чтобы избежать перегрузки API или превышения лимита запросов.

## 3.2. Пример промпта

```md

```


## 3.3. concepts.json

- Список используемых понятий и страничек сохранить в файле `concepts.json` в директории `WORK`.

- роль этого файла

- Используйте файл **concepts.json** для поиска понятий и расставления ссылок в текстах


## 3.4. Расстановка ссылок в тексте

### Вход
- Путь к директории с файлами Markdown (.md) — переменная `PATH` (строка, например, `'pages'`).
- Опциональный файл `names.md` с паттернами (список строк); если отсутствует, паттерны берутся из имен файлов в директории.
### Выход
- Обновленные файлы Markdown в директории `PATH` с добавленными ссылками в формате `[[текст|паттерн]]`, где текст сохраняет исходные падежи, а паттерн указывает на связанное имя или страницу.
### Алгоритм
1. **Сбор данных**: Функция `get_pages` читает все .md файлы из директории `PATH`, создавая словарь `{имя_файла: текст}`.
2. **Определение паттернов**: Если файл `names.md` существует, паттерны читаются из него; иначе `get_names` извлекает имена из ключей словаря файлов.
3. **Нормализация текста и паттернов**: В `add_links` текст разбивается на слова, каждое нормализуется через `morph.parse(word)[0].normal_form` (именительный падеж, единственное число) с помощью `pymorphy3`; паттерны нормализуются аналогично.
4. **Поиск совпадений**: Алгоритм Ахо-Корасика в `build_automaton` и `search_text` ищет позиции нормализованных паттернов в нормализованном тексте, возвращая словарь `{паттерн: [оригинальный_паттерн, позиции]}`.
5. **Добавление ссылок**: Для каждой найденной позиции в исходном тексте (сохраняя оригинальные слова с падежами) вставляется разметка `[[текст|паттерн]]`, где `текст` — фрагмент исходного текста, а `паттерн` — связанное имя; результат собирается в новый словарь `{имя_файла: обновленный_текст}`.
6. **Запись результата**: Функция `update_pages` переписывает файлы в директории `PATH` с обновленным содержимым из нового словаря.


## 4. Выводы

